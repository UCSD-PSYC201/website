[["index.html", "UCSD Psyc 201ab / CSS 205 / Psyc 193 Welcome", " UCSD Psyc 201ab / CSS 205 / Psyc 193 Welcome This is the website for Psych 201a, 201b; they are presumed to be taken as a series with 201a in the fall, and 201b in the winter. 201a is also offered as an advanced undergraduate course (Psych 193), and will be crosslisted as the core stats class for the Computational Social Science MS program (CSS 205). 201a covers statistical graphics, probability, classical statistical methods, with an emphasis on the general linear model, and their implementation in R. 201b covers more advanced models and methods, including generalized linear models, multilevel/hierarchical regression, and computational approaches such as numerical optimization, Monte Carlo, and resampling. 201b is not offered in the 2021-2022 academic year "],["course-syllabus.html", "Syllabus Instructors Class meetings Grading Class Resources", " Syllabus Instructors Instructor Office hours Ed Vul TBD Wenhao (James) Qi Thursdays 10am in 3509 Mandler Class meetings Class meetings will be in 3545 Mandler Hall. Lectures are Tuesday / Thursday 2-4. Labs are Wednesdays 5-7. Attendance is not required, but is generally helpful. Grading PSYC 201 / CSS 205: Homework (25%), Midterm (25%), Final (25%), Project (25%). PSYC 193: Homework (75%), Project (25%). (no midterm or final) Details: Homework: These are entirely in R, on our online system. It makes sense to seek help from other students when you get stuck, but make sure you do everything yourself, so that you will be able to do it on your own in exams, and more importantly, real life. Exams: Midterm and Final (both take home). Working together on exams is prohibited. Group project: You will analyze some data, write a final report, and make a presentation. Details here. Class Resources Class Campuswire: Sign up here, code is 2647. All class communication will be here. Homework assignments: login (this may be buggy, please do not hesitate to tell us if something is wrong. ) Login is your ucsd username, password is full student ID, including letter. Readings: Generally we will draw on a number of sources, and our own notes, as needed for whatever we are covering. Software: We are using R and the Rstudio IDE. Our own installation instructions and list of starter resources: Getting started with R "],["course-201a.html", "201a Schedule Week 0: Introduction Week 1: Data Week 2: Visualization Week 3: Theoretical foundations Week 4: Linear model: Regression Week 5: Linear model: Multiple regression Week 6: Linear model: Categorical predictors Week 7: Linear model: ANCOVA, diagnostics Week 8: Linear model: Linearizing transforms Week 9: Covarying errors (repeated measures / random effects) Week 10: Review and preview", " 201a Schedule Week 0: Introduction In which we will cover the goals of this class, and where the class materials fit into the broader landscape of quantitative / computational / data skills. Readings Basic introduction to R / Rstudio: R4DS Sections: 1, 4, 6, 8 Homework Pre-survey Thursday Overview: slides Week 1: Data In which we cover data organization, cleaning, and basic summaries, while getting acquainted with R syntax. Readings Working with data: R4DS Sections: 5, 7, 11, 12 Homework data cleaning Tuesday Data overview: slides live code Wednesday Thursday Week 2: Visualization In which we cover how to make scientifically useful graphs. Readings [notes] R4DS: 2, 3 socviz: make a plot (the rest of this book may also be useful, but we don’t have time for a thorough treatment.) Homework data visualization Tuesday Wednesday Thursday Week 3: Theoretical foundations In which we cover probability theory, and the logic of classical statistical methods. Readings Probability notes: terms basics conditional monte-carlo random-variables distribution functions expectation central limit theorem, normal NHST notes: via simulation sampling distribution basic NHST via normal power, effects bonus: via binomial Homework NHST probability Due: 2020-10-28 Tuesday slides: probability Wednesday Probability [code] [answers] Thursday slides: NHST Week 4: Linear model: Regression Notes t-distribution t-tests (note: some of this will be covered in week 6 and week 10) bivariate data anscombe’s quartet covariance correlation ordinary least-squares regression yx,xy,pca coefficient of determination significance testing of these measures prediction regression diagnostics Homework Regression Due: 2020-11-04 Tuesday slides Wednesday Regression [code] [answers] Thursday slides Week 5: Linear model: Multiple regression Notes multiple regression Tuesday slides code Wednesday Multiple regression [code] [answers] Thursday slides Week 6: Linear model: Categorical predictors Readings / Notes Notes on t-tests [howell ch.13 on ANOVA] [howell ch.16 on ANCOVA] Homework Multiple regression Due: 2020-11-20 Tuesday slides Thursday slides Week 7: Linear model: ANCOVA, diagnostics Homework ANOVA &amp; ANCOVA Due: 2020-11-30 Tuesday slides Wednesday ANOVA [code] [answers] Thursday slides Week 8: Linear model: Linearizing transforms Homework Linearizing transforms Due: 2020-12-03 Tuesday slides Week 9: Covarying errors (repeated measures / random effects) Readings: I don’t like either of these…. I am still on the hunt for a pithy conceptual overview of repeated measures designs and analyses: This is simpler: Howell, ch. 14 This is mathier: Kutner ch. 27 Tuesday slides Wednesday Repeated measures [code] [answers] Readings [Howell (basic)] [Kutner (mathy)] Week 10: Review and preview Tuesday Mixed effects model brief Project Q&amp;A, Review Q&amp;A slides Wednesday R Review (for final) Thursday Review "],["course-projects.html", "Projects Examples of this sort of thing 201a 201b Data sources", " Projects The goal is to analyze a large, rich dataset to answer an interesting behavioral/social/neural question, with the final product being a potentially publishable paper. This project is divided into two phases to be implemented in 201a and 201b. In 201a your goal is to identify a conjunction of an interesting question and a data source that might answer it. You will need to understand the data, clean it, make graphs of the data that might answer the question, and do simple analyses to get your bearings. In 201b you will do the more complete analyses, likely using more advanced methods that we will cover in 201b, and turn the initial report from 201a into something that could be submitted for publication. Examples of this sort of thing skill learning in online games sequential dependence in yelp reviews stereotype threat in chess play income mobility over time scaling laws in cities crowd within in real estimation personality in blog posts neurosynth brain mapping example hashtag adoption cultural tastes via baby names You will notice that particularly successful examples usually have a combination of a few things: a coherent research question, with a good justification for why the naturalistic data maps onto theoretical constructs of interest; a novel dataset, which might mean data that had not preciously been available, or a dataset that was created by cleverly combining/co-registering previously separate datasets; and (sometimes or) a fairly sophisticated analysis that adequately grapples with the complicated structure of the data. The full project will span both 201a and 201b (previously I had it only in 201b, and that was not enough time) 201a 201a Timeline Figure out groups as soon as possible, so we can assist if folks are group-less. 2020-10-20: Groups due 2020-10-27: Project plan due 2020-11-10: Preliminary data summaries due 2020-12-17: (before final) Write-ups due 2020-12-17: (during final) Project presentations 2020-12-18: Group-evaluation due Groups You will be in groups of ~3-5 (5 if group includes an undergrad). Undergrads should not be in a group together (should join a group of grad students). Hopefully you can self-assemble into groups, but I will help if need be. Due: 2020-10-20 Create a Slack channel titled “project-[groupname]” (can be either public or private). Invite Ed and James into the channel. Upload a CSV file about your group makeup in the channel: 1 row per group member, and columns: last_name, first_name, email, group_name. 201a Project plan Due: 2020-10-27 This is just a message including the following: Description: (500 words max) describe the research question(s), the data source(s), and how they are related. the data 201a Preliminary data summaries Due: 2020-11-10 This is an R script (ideally an R markdown file), and output showing coarse summaries of the data (histograms, scatterplots, etc). This should include various validity checks to figure out if any of the data are corrupted, if co-registration of different data sources was done accurately, etc. Send the R script and output in the Slack channel. The only goal here is to force you to look over the data to make sure you find problems early, rather than at the last minute. 201a Write-ups Due: 2020-12-17, before class This should be less than 2000 words, and should include: A description of the research questions: why is this an interesting/important question? Add a bit of lit review to help others understand what is already known, and what missing information your approach aims to provide. A description of the data, where it came from, any peculiarities about the data structure or collection method, etc. Graphs that try to answer the key research questions, and some explanation about why the graphs answer (or fail to answer) these research questions. Some basic statistics that attempt to quantify the answers to these research questions and the uncertainty associated with these answers (only methods covered in 201a are expected, but by all means do something fancier if you are comfortable) Some discussion about which questions are adequately answered by the methods you used, and which will require a more elaborate analysis. (e.g., we fit a regression to all the data, but we know there is important substructure that this analysis is ignoring) 201a Presentation Due: 2020-12-17, during final time Tell us about your results. This should be like a 10 minute conference talk: provide motivation for the question you are asking, and explain why it is worth asking describe (briefly) what was done on this question previously, and why your project fills a gap in knowledge describe the data, any peculiarities therein, and explain why it is a useful data source for answering the question. what are the linking assumptions? present your results (mostly graphs), and explain what we learn from these graphs. describe the caveats, to set the agenda for what you might try to address in 201b. The goals here are: to teach the audience (us instructors, and the rest of the class) about this research domain/question keep the audience entertained practice working through the logic tying questions to data practice making nice data visualizations in R to highlight the relevant results practice giving talks. Do not go into agonizing details about the trials and tribulations involved with your R code, your reanalysis, etc. Just give us your results. 201a Group-evaluation Due: 2020-12-18 After you completed your presentation, each student should independently DM Ed on Slack: your group name, and your estimate as to what percentage of the total work each member of your group did. Basically, I want to know if someone single-handedly carried your group, or if someone was a free-rider and let the rest of the group do all the work. I’m hoping that there will not be such an uneven distribution of effort, and that the mere fact that these evaluations will be sent will motivate your group not to leave you hanging. 201b In 201b you will start where you left off in 201a: fill in the missing analyses, flesh out the motivation/introduction, add a proper discussion, and hopefully, wind up with a paper that might be submitted for publication with minimal further effort. Data sources The lists below are just pointers, you should do your own googling, and hopefully you will find something new and interesting. In general, you will get the most mileage in doing something new by intelligently combining several sources that have not already been combined for you (e.g., cross-linking crime statistics for a city with city demographics, or fluctuations in attitudes over time/geography, with voting patterns at that time/place, etc). General social science survey: http://www3.norc.org/Gss+website/ data.gov: http://www.data.gov/ census datasets: https://www.census.gov/data/developers/data-sets.html FBI crime statistics: http://www.fbi.gov/stats-services/crimestats Perhaps useful forum: http://opendata.stackexchange.com/ List of random data sets: http://rs.io/100-interesting-data-sets-for-statistics/ FAA datasets: https://www.faa.gov/data_research/aviation_data_statistics/data_downloads/ FDIC (retail banking) datasets: https://www2.fdic.gov/idasp/warp_download_all.asp Fuel economy information from the EPA: http://www.fueleconomy.gov/feg/download.shtml NIH funding information (may be difficult to pull data into a usable format): http://report.nih.gov/nihdatabook/index.aspx Personality test data: http://personality-testing.info/_rawdata/ Drug use data: http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/34933?q=&amp;paging.rows=25&amp;sortBy=10 CDC health and nutrition: http://www.cdc.gov/nchs/nhanes/nhanes_questionnaires.htm American Sign Language corpus: http://www.bu.edu/av/asllrp/dai-asllvd.html OpenPsychometrics: https://openpsychometrics.org/tests/OSRI/ Large, but likely tricky data set to analyze: https://gigaom.com/2014/05/29/more-than-250-million-global-events-are-now-in-the-cloud-for-anyone-to-analyze/ Datasets available upon request: Dundee eye-tracking: http://www.dundee.ac.uk/psychology/staff/profile/alan-kennedy List of somewhat small data sets, more suited to small class examples rather than posing new questions: http://www.calvin.edu/~stob/data/ More lists here: http://opendata.stackexchange.com/questions/266/a-database-of-open-databases http://stats.stackexchange.com/questions/7/locating-freely-available-data-samples https://github.com/rasbt/pattern_classification/blob/master/resources/dataset_collections.md https://www.kaggle.com/datasets?sortBy=votes&amp;group=all https://cseweb.ucsd.edu/~jmcauley/datasets.html https://aminer.org/citation Other lists I found while googling for “public social science data sources” http://socsciresearch.com/r6.html http://ciser.cornell.edu/ASPs/datasource.asp?CATEGORY=2 http://personality-testing.info/_rawdata/ http://veekaybee.github.io/2018/07/23/small-datasets/ http://blog.yhat.com/posts/7-funny-datasets.html https://vincentarelbundock.github.io/Rdatasets/datasets.html http://biostat.mc.vanderbilt.edu/wiki/Main/DataSets https://www.kaggle.com/datasets "],["R-start.html", "Getting started with R Installing R Introduction to R Better data analysis code.", " Getting started with R Installing R Download and install R for your system: https://cran.rstudio.com/ Download and install RStudio for your system: https://www.rstudio.com/products/rstudio/download/ Packages We will use a number of packages that extend the functionality of basic R, and make some operations easier/more intuitive. You can start by installing the tidyverse package using the code below. install.packages(&#39;tidyverse&#39;) Introduction to R Writing analyses in R is writing code. If you are new to this notion, you might benefit from this excellent article on what code is, from this discussion of the two cultures of computer users, and from this harsh, but accurate description of what it takes to really learn to code Getting started There’s a large set of introductory tutorials to R online, easily accessible via google. I recommend working through some interactive tutorials to start yourself off: Try R from codeschool swirl offers interactive R lessons run within R datacamp offers interactive tutorials, but I’m a bit confused what is free, and what requires subscription Here is a handy tutorial R script OpenIntro stats also R labs Rstudio offers a list of such lessons As you become familiar with the basics, you may want some quick reference sources. Take a look at Rstudio cheat sheets, in particular data visualization and data wrangling This one is also useful Take a look at Wickham’s list of basic R functions worth learning Cookbook for R offers solutions and code snippets for common problems. You will need to find help. Google “R [what you want to do]” CrossValidated is a great resource: I often find solutions to my problems there. You may also want to consult more advanced lessons to supplement labs/notes: This UBC course offers great notes on modern and practical R (including ggplot) Hadley Wickham’s advanced R book and online notes are very good, but advanced, as described To write code well, you will need to know something about how a computer works. General command line tutorials are good for understanding how CLIs work. e.g., learn enough command line to be dangerous Understand your system’s directory and file structure and how to navigate it from a console. In R: getwd(), setwd(), list.files(). Once you can actually write some code, it is worth learning to make it good. Good code is readable by humans and self documenting This can be achieved by adopting a consistent and sensible style of code. A few suggestions: Google R style guide, and Wickham’s style guide. Avoid magic numbers. They make your code hard to read and brittle to change. Use unique and meaningful names for scripts, functions, variables, data.frames, columns, etc. Learn to type well, and pay attention to text details. In most programming languages, letter order, letter case, visually similar symbols, etc. have to be correct for a computer to understand what you are saying. Human readers are forgiving with typos, computers are not. Learn to use your IDE (in our case, Rstudio). Tab completion is amazing. Keyboard shortcuts are very handy. Better data analysis code. The overarching flow of data analysis is something like: data -&gt; pre-processing code -&gt; clean data -&gt; analysis code -&gt; results -&gt; presentation code -&gt; figures, tables, numbers It is helpful to factor your code this way, as it allows you to muck around with various parts without disrupting the others. A few suggestions for how to write good code for data analysis. Make sure analysis code is state independent (it should re-run correctly after rm(list=ls())), and self-sufficient (it should not require any human intervention, mouse-clicks, etc). All of this ensures that re-running your analysis is not a pain, and is reproducible. Don’t arbitrarily create data subsets stored in assorted variables – that’s a great way to make a mess of your code and confuse yourself. Subset data as needed, while keeping the data frame complete. Build complicated commands piece by piece in the console, then assemble the final compact command in your script. Especially when using dplyr pipes (%&gt;%), or nesting functions. When in doubt about whether the code is intuitive, pass named, rather than positional, arguments to functions. Take explicit control of your data types and structures – don’t just assume that when you read in a csv file, all variables, factors, etc. have the correct data type, names, etc. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
